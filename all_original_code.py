# -*- coding: utf-8 -*-
"""Wagner&Brouwer.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1vNKF9dY2-NC-RhwFWQ5mple3vWXTfo8T
"""

import torch
import torch.nn as nn
import torch.optim as optim
import torch.nn.functional as functionals
from torch.utils.data import DataLoader, TensorDataset, random_split
from torchsummary import summary

!pip install torch_geometric

import torch_geometric
from torch_geometric.utils import from_networkx

import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
from tensorflow.keras import optimizers
from tensorflow.keras import metrics
from tensorflow.keras import regularizers
from tensorflow.keras.callbacks import ReduceLROnPlateau

from sklearn.model_selection import KFold, StratifiedKFold, cross_val_score, train_test_split
from sklearn.neural_network import MLPClassifier, MLPRegressor
from sklearn.metrics import log_loss, mean_squared_error

import matplotlib.pyplot as plt
import networkx as nx
import numpy as np
import math
import itertools as it
import random

!pip install gymnasium
import gymnasium as gym

!pip install spektral
import spektral as sp

import json
import pathlib
import copy
import h5py
from collections import defaultdict
import sys

from google.colab import drive
drive.mount('/content/drive')

path = '/content/drive/My Drive/RL e Grafi/Graphs Database/'

def data_collector(folder, V, conn):
  """
  Collects and reads a graph data file in .g6 (Graph6) format from a specified folder.

  Parameters:
  - folder (str): Directory path for .g6 files, taken from http://users.cecs.anu.edu.au/~bdm/data/graphs.html.
  - V (int or str): Number of nodes, used in the filename.
  - conn (bool): If True, the file .g6 contains all *connected* graphs with V nodes; otherwise, it contains all graphs with V nodes.

  Returns:
  - A NetworkX graph object from the .g6 file, containing all (connected) graphs with V nodes.
  """

  if conn == True:
    data = f"graph{V}c.g6"
  elif conn == False:
    data = f"graph{V}.g6"
  data = str(data)
  folder += data
  return nx.read_graph6(folder)

C = data_collector(path, 8, True)
L = data_collector(path, 8, False)

def dict_to_arr(dict):
  """
  Converts a dictionary into a numpy array.

  Parameters:
  - dict (dictionary): The dictionary to be converted. Keys are expected to be integers from 0 to len(dict)-1.

  Returns:
  - X (numpy array): A column vector where the i-th element is the value of the i-th key in the dictionary.
  """

  v = len(dict)
  X = np.zeros((v,1))
  for i in range(v):
    X[i,0] += dict[i]
  return X

def cut_nodes(G):
  """
  Creates a list of graphs, each one being a copy of the original graph with one node removed.

  Parameters:
  - G (NetworkX graph): The original graph.

  Returns:
  - cuts (list): A list of graphs. Each graph in the list is a copy of the original graph with one node removed.
  """

  v = G.number_of_nodes()
  cuts = [copy.deepcopy(G) for _ in range(v)]
  for i in range(v):
    cuts[i].remove_node(i)
  return cuts

class feats_miner():
  """
  A class used to mine features from a graph using various graph invariants and metrics.
  """
  def __init__(self, V):
    """
    Initializes the class with the number of nodes and defines a set of graph invariants and metrics.
    """
    self.num_nodes = V

    self.invariants = {'card(E)': lambda G: nx.number_of_edges(G),
                       'num_cc': lambda G: nx.number_connected_components(G),
                       'adj_sp': lambda G: np.real(nx.adjacency_spectrum(G)),
                       'lapl_sp': lambda G: nx.laplacian_spectrum(G),
                       'wagner-1': lambda G: self.wagner_score_max(G),
                       'brouwer': lambda G: self.brouwer_vector(G),
                       }

    self.invariants_conn = {'dist': lambda G: self.dist_matrix(G),
                            'prox_ind': lambda G: self.prox_index(G),
                            'prox_sp': lambda G: np.linalg.eigh(self.dist_matrix(G))[0],
                            'diam': lambda G: nx.diameter(G),
                            'wagner-2': lambda G: self.wagner_score_dist(G),
                            }

    # Used to distinguish scalar from vector from matrix features
    self.hierarchy = {'card(E)': 0,
                      'num_cc': 0,
                      'adj_sp': 1,
                      'lapl_sp': 1,
                      'wagner-1': 0,
                      'brouwer': 1,
                      'dist': 2,
                      'prox_ind': 0,
                      'prox_sp': 1,
                      'diam': 0,
                      'wagner-2': 0,
                      }


  def dict_to_arr(self, dict):
    """
    Converts a dictionary into a numpy array.

    Parameters:
    - dict (dictionary): The dictionary to be converted. Keys are expected to be integers from 0 to len(dict)-1.

    Returns:
    - X (numpy array): A 1D array where the i-th element is the value of the i-th key in the dictionary.
    """
    v = len(dict)
    X = []
    for i in range(v):
      X.append(dict[i])
    return np.array(X)

  def brouwer_vector(self, G):
    spec = nx.laplacian_spectrum(G)
    V = len(spec)
    B = []
    eig_sum = 0
    for t in range(V-1,-1,-1):
      eig_sum += spec[t]
      m = G.number_of_edges()
      c = math.comb(V+1-t,2)
      score = eig_sum - (m+c)
      B.append(score)
    return np.array(B)



  def prox_index(self, G):
    v = nx.number_of_nodes(G)
    M = self.dist_matrix(G)
    e = np.ones(v)
    p = (1/(v-1)) * M.dot(e)
    return min(p)

  def wagner_score_max(self, G):
    const = 1+np.sqrt(self.num_nodes-1)
    radius = max(np.real(nx.adjacency_spectrum(G)))
    weight = len(nx.max_weight_matching(G))
    return const - (radius + weight)

  def wagner_score_dist(self, G):
    p = self.prox_index(G)
    spec = np.linalg.eigh(self.dist_matrix(G))[0].tolist()
    spec.sort(reverse=True)
    d = nx.diameter(G)
    k = math.floor((2*d)/3)
    return -(p + spec[k])



  def deg(self, G, depth):
    v = nx.number_of_nodes(G)
    if v == 0:
      return np.array([0])
    A = nx.adjacency_matrix(G)
    A = A.todense()
    const = np.ones(v)
    pow = np.linalg.matrix_power(A,depth)
    return pow.dot(const)



  def walk(self, G, length):
    v = nx.number_of_nodes(G)
    if v == 0:
      if length == 0:
        return np.array([[1]])
      else:
        return np.array([[0]])
    A = nx.adjacency_matrix(G)
    A = A.todense()
    return np.linalg.matrix_power(A,length)

  def dist_matrix(self, G):
    v = nx.number_of_nodes(G)
    M = nx.adjacency_matrix(G)
    M = M.todense()
    for i in range(v-1):
      for j in range(i+1, v):
        try:
          d = nx.shortest_path_length(G,i,j)
        except nx.NetworkXNoPath:
          d = None
        except nx.NodeNotFound:
          d = None
        if d != None and d > 1:
          M[i,j] += d
          M[j,i] += d
    return M

  def gen_dist_matrix(self, G):
    v = nx.number_of_nodes(G)
    cc = nx.number_connected_components(G)
    subs = [copy.deepcopy(G) for _ in range(cc)]
    comp = list(nx.connected_components(G))
    matx = {}
    for i in range(cc):
      tag = ''
      for n in comp[i]:
        tag += str(n)
      subs[i] = subs[i].subgraph(comp[i])
      M = self.dist_matrix(subs[i])
      matx[tag] = M
    return matx



  def mine(self, G, feats_dict):
    H = copy.deepcopy(G)
    tag = ''
    for n in H:
      tag += str(n)
    out = {}
    for I in feats_dict:
      out[I] = feats_dict[I](H)
    return tag, out

  def surgery(self, G, f):
    if f == 0:
      null = nx.null_graph()
      return [copy.deepcopy(G)], [copy.deepcopy(null)]
    if f == self.num_nodes:
      null = nx.null_graph()
      return [copy.deepcopy(null)], [copy.deepcopy(G)]
    nodes = list(range(self.num_nodes))
    combs = list(it.combinations(nodes, f))
    subs = [copy.deepcopy(G) for _ in range(len(combs))]
    cuts = [copy.deepcopy(G) for _ in range(len(combs))]
    for c in range(len(combs)):
      subs[c] = subs[c].subgraph(combs[c])
    for c in range(len(combs)):
      for t in range(len(combs[c])):
        cuts[c].remove_node(combs[c][t])
    return subs, cuts

  def filtration(self, G, f, feats):
    injs, projs = self.surgery(G, f)
    injs_feats = {}
    projs_feats = {}
    new_invariants = {}
    new_hierarchy = {}
    for i in range(len(feats)):
      name = feats[i]
      if name.endswith('-deg'):
        d = int(name.replace("-deg", ""))
        new_invariants[name] = lambda G, d=d: self.deg(G, d)
        new_hierarchy[name] = 1
      elif name.endswith('-walk'):
        l = int(name.replace("-walk", ""))
        new_invariants[name] = lambda G, l=l: self.walk(G, l)
        new_hierarchy[name] = 2
      else:
        new_invariants[name] = self.invariants[name]
        new_hierarchy[name] = self.hierarchy[name]
    for t in range(len(injs)):
      tag_i, fields_i = self.mine(injs[t], new_invariants)
      injs_feats[tag_i] = fields_i
      tag_p, fields_p = self.mine(projs[t], new_invariants)
      projs_feats[tag_p] = fields_p
    return injs_feats, projs_feats, new_hierarchy

  def filt_stack(self, filtration, hierarchy):
    scalars = []
    vects = []
    matrx = []
    for key in hierarchy:
      if hierarchy[key] == 0:
        scalars.append(key)
      elif hierarchy[key] == 1:
        vects.append(key)
      elif hierarchy[key] == 2:
        matrx.append(key)
    p = len(scalars)
    q = len(vects)
    r = len(matrx)
    sca = []
    vec = []
    mat = []
    for tag in filtration:
      if len(tag) == self.num_nodes:
        for t in range(p):
          sca.append(filtration[tag][scalars[t]])
        sca = np.array(sca)
        for t in range(q):
          vec.append(filtration[tag][vects[t]])
        vec = np.stack(vec)
        for t in range(r):
          mat.append(filtration[tag][matrx[t]])
        mat = np.stack(mat)
        print(f"vector of {len(sca)} scalar features (Graph-Invariants)")
        print(sca)
        print(f"matrix of node features ({len(vec)}xV)")
        print(vec)
        print(f"tensor of edge features ({len(mat)}xVxV)")
        print(mat)
    return sca, vec, mat



path_exp = '/content/drive/My Drive/RL e Grafi/Esperimenti Wagner&Brouwer/'

class ExperimentData:
  def __init__(self, target_score, path=path_exp):
    self.path = pathlib.Path(path + target_score)
    self.path.mkdir(parents=True, exist_ok=True)
    self.data_path = None
    self.groups_path = {}
    self.subgroups_dep = {}

  def load_database(self, env_name):
    self.data_path = self.path / (env_name + '.hdf5')
    try:
      with h5py.File(self.data_path, 'a') as file:
        for group_name in file.keys():
          self.groups_path[group_name] = str(self.data_path / group_name)
          for subgroup_name in file[group_name].keys():
            self.subgroups_dep[subgroup_name] = group_name
    except Exception as e:
      print(f"Failed to create HDF5 file at {self.data_path}: {e}")

  def add_group(self, group_name, meta=None):
    try:
      with h5py.File(self.data_path, 'a') as file:
        grp = file.create_group(group_name)
        if meta is not None:
          for key, value in meta.items():
            file[group_name].attrs[key] = value
        self.groups_path[group_name] = str(self.data_path / group_name)
    except ValueError:
      print(f"Group '{group_name}' already exists.")
    except Exception as e:
      print(f"Failed to create group {group_name} in HDF5 file at {self.data_path}: {e}")

  def get_group_meta(self, env):
    meta = {}
    meta['num_nodes'] = env.num_nodes
    meta['rew_type'] = env.rew_type
    return meta

  def up_group_meta(self, group_name, meta):
    try:
      with h5py.File(self.data_path, 'a') as file:
        if group_name in file:
          for key, value in meta.items():
            file[group_name].attrs[key] = value
        else:
          print(f"The group '{group_name}' does not exist in the file.")
    except Exception as e:
        print(f"Failed to open HDF5 file at {self.data_path}: {e}")

  def add_subgroup(self, parent_group, subgroup_name, meta=None):
    if subgroup_name not in self.subgroups_dep:
      self.subgroups_dep[subgroup_name] = parent_group
    try:
      with h5py.File(self.data_path, 'a') as file:
        parent_group = file[parent_group]
        subgroup = parent_group.create_group(subgroup_name)
        if meta is not None:
          for key, value in meta.items():
            file[parent_group][subgroup_name].attrs[key] = value
    except ValueError:
      print(f"Subgroup '{subgroup_name}' already exists.")
    except Exception as e:
      print(f"Failed to create subgroup {subgroup_name} in HDF5 file at {self.data_path}: {e}")

  def add_simulation(self, subgroup_name, sim_name, simulation, meta=None):
    parent = self.subgroups_dep[subgroup_name]
    adjs, sarx = simulation
    try:
      with h5py.File(self.data_path, 'a') as file:
        subgroup = file[parent + '/' + subgroup_name]
        datasets = list(subgroup.keys())
        if any(ds.startswith(sim_name) for ds in datasets):
          print(f"Simulation name '{sim_name}' already taken.")
        else:
          subgroup.create_dataset(sim_name + '_adjs', data=adjs)
          subgroup.create_dataset(sim_name + '_sarx', data=sarx)
          if meta is not None:
            for key, value in meta.items():
              subgroup[sim_name + '_adjs'].attrs[key] = value
              subgroup[sim_name + '_sarx'].attrs[key] = value
    except Exception as e:
      print(e)

class LinEnv(gym.Env):
    def __init__(self, num_nodes, score='wagner-1', rew_type='sparse', conn=True):
        super(LinEnv, self).__init__()
        self.name = 'linear'
        self.rew_types = {'sparse','sparse_max','cont','cont_var'}
        self.rew_type = rew_type
        self.score_fun = score
        self.num_nodes = num_nodes
        self.conn = conn
        self.miner = feats_miner(self.num_nodes)
        self.score_ev = self.miner.invariants[self.score_fun]
        self.obs_dim = self.num_nodes * (self.num_nodes-1)
        self.num_edges = int(self.obs_dim//2)
        self.pointer = copy.deepcopy(self.num_edges)
        self.observation_space = gym.spaces.MultiBinary(self.obs_dim)
        self.initial_state = np.zeros(self.obs_dim)
        self.initial_state[self.num_edges] += 1
        self.state = copy.deepcopy(self.initial_state)
        self.action_space = gym.spaces.Discrete(2)
        self.reward_range = (-float('inf'), float('inf'))
        self.initial_adj = np.zeros((self.num_nodes,self.num_nodes))
        self.adj = copy.deepcopy(self.initial_adj)
        self.initial_ST = np.zeros((self.num_nodes,2))
        self.initial_ST[0,0] += 1
        self.initial_ST[1,1] += 1
        self.ST = copy.deepcopy(self.initial_ST)
        self.initial_graph = nx.Graph(self.initial_adj)
        self.graph = copy.deepcopy(self.initial_graph)
        self.initial_scores = {'sparse': 0, 'sparse_max': 0, 'cont': self.score_ev(self.graph), 'cont_var': self.score_ev(self.graph)}
        self.initial_score = copy.deepcopy(self.initial_scores[rew_type])
        self.score = copy.deepcopy(self.initial_score)
        self.score_traj = [copy.deepcopy(self.initial_score)]
        self.done = False
        self.history = []

    def time_up(self, i, j):
      if j == self.num_nodes-1:
        i += 1
        j = i + 1
      else:
        i = i
        j += 1
      return i, j

    def step(self, action):
        sarsd = [0,0,0,0,0]
        h = self.obs_conversion()
        sarsd[0] = h
        sarsd[1] = action
        st = np.nonzero(self.ST)[0].tolist()
        i, j = st[0], st[1]
        t = self.pointer
        index = np.zeros(self.obs_dim)
        index[t] -= 1
        self.state += index
        self.ST[i,0] -= 1
        self.ST[j,1] -= 1
        done = copy.deepcopy(self.done)
        reward = 0
        if self.pointer == self.obs_dim-1:
          done = True
          self.done = done
        if action == 1:
          self.state[self.pointer-self.num_edges] += 1
          self.adj[i,j] += 1
          self.adj[j,i] += 1
          self.graph = nx.Graph(self.adj)
          self.score = self.score_ev(self.graph)
        self.score_traj.append(copy.deepcopy(self.score))
        if not done:
          self.pointer += 1
          self.state[self.pointer] += 1
          i, j = self.time_up(i,j)
          self.ST[i,0] += 1
          self.ST[j,1] += 1
        next_state = copy.deepcopy(self.state)
        if self.rew_type == 'sparse':
          if done:
            if self.conn == True:
              if self.miner.invariants['num_cc'](self.graph) != 1:
                reward = -1000000.0
              else:
                reward = self.score
            else:
              reward = self.score
        if self.rew_type == 'sparse_max':
          if done:
            reward = max(self.score_traj)
        if self.rew_type == 'cont':
          reward = self.score
        if self.rew_type == 'cont_var':
          reward = self.score_traj[-1] - self.score_traj[-2]
        sarsd[2] = reward
        h_up = self.obs_conversion()
        sarsd[3] = h_up
        sarsd[4] = int(done)
        self.history.append(sarsd)
        return next_state, reward, done

    def render(self):
      nx.draw(self.graph, with_labels=True)
      plt.show()
      plt.close()

    def obs_conversion(self):
      e = self.num_edges
      ist = copy.deepcopy(self.state)
      st = copy.deepcopy(self.ST)
      st = np.nonzero(st)[0].tolist()
      id = int(np.dot(ist[:e], 2**np.arange(e)))
      if st == []:
        st = [0,0]
        return (id, 0, 0)
      else:
        return (id, st[0], st[1])

    def reset(self):
        self.state = copy.deepcopy(self.initial_state)
        self.adj = copy.deepcopy(self.initial_adj)
        self.ST = copy.deepcopy(self.initial_ST)
        self.score = copy.deepcopy(self.initial_score)
        self.pointer = copy.deepcopy(self.num_edges)
        self.score_traj = [copy.deepcopy(self.initial_score)]
        self.done = False
        self.history = []
        return self.initial_state, self.initial_score, self.done

class Agent():
    def __init__(self, Env, Net, l_r, conn_check=True):
      self.policy = Net
      self.env = Env
      self.learning_rate = l_r
      self.criterion = torch.nn.BCELoss()
      self.optimizer = torch.optim.SGD(self.policy.parameters(), lr=self.learning_rate)
      self.objective = 0
      self.baseline = -100
      self.success_hist = []
      self.loss_hist = []


    def reset(self):
      self.objective = 0
      self.baseline = -100
      self.success_hist = []
      self.loss_hist = []
      return

    def policy_sample(self):
      self.env.reset()
      sts = []
      acts = []
      graphs = []
      while not self.env.done:
        sts.append(torch.Tensor(copy.deepcopy(self.env.state)))
        act = int(torch.bernoulli(self.policy(sts[-1])).item())
        acts.append(act)
        graphs.append(copy.deepcopy(self.env.graph))
        self.env.step(act)
      rews = copy.deepcopy(self.env.score_traj)
      final_graph = copy.deepcopy(self.env.graph)
      return sts, acts, graphs, final_graph, rews

    def sample_process(self,sample):
      valid_rews = []
      if self.env.miner.invariants['num_cc'](sample[3]) != 1:
        return None
      else:
        final_rew = sample[4][-1]
        for p in range(self.env.num_edges-1,-1,-1):
          if self.env.miner.invariants['num_cc'](sample[2][p]) == 1:
            valid_rews.append(sample[4][p])
          else:
            break
        if valid_rews == [] or (final_rew > max(valid_rews)):
          Tens_sts = torch.stack(sample[0])
          Tens_acts = torch.Tensor(sample[1])
          value = final_rew
          graph = sample[3]
          return Tens_sts, Tens_acts, value, graph, self.env.num_edges
        else:
          num_valid_graphs = len(valid_rews)
          valid_rews.reverse()
          value = max(valid_rews)
          t = valid_rews.index(value)
          t += self.env.num_edges - num_valid_graphs
          graph = sample[2][t]
          Tens_sts = torch.stack(sample[0])
          for l in range(t+1,self.env.num_edges):
            Tens_sts[l,:self.env.num_edges] = Tens_sts[t,:self.env.num_edges]
          Tens_acts = Tens_sts[-1,:self.env.num_edges]
          return Tens_sts, Tens_acts, value, graph, t

    def one_shot_training(self,num_steps,num_eps):
      steps = num_steps
      num_trains = 0
      while steps > 0:
        curr_objective = copy.deepcopy(self.baseline)
        Y = self.policy_sample()
        X = self.sample_process(Y)
        if X == None:
          print("Invalid game")
        else:
          print(f"Current best score: {X[2]}")
          if X[2] > self.objective:
            print(f"Objective achieved in {num_steps-steps} rounds by:")
            nx.draw(X[3])
            plt.show()
            plt.close()
            self.success_hist += [X[3]]
            print(f"at position {X[4]}")
            for t in range(num_eps):
              preds = self.policy(X[0]).squeeze()
              L = self.criterion(preds,X[1])

              self.optimizer.zero_grad()
              L.backward()
              self.optimizer.step()
              self.loss_hist.append(L.item())
              if t == num_eps-1:
                print(f"Loss: {L}")
            self.baseline = copy.deepcopy(self.objective)
            self.objective = X[2]
            return X
          elif X[2] > curr_objective:
            print("Current task passed, learning from:")
            nx.draw(X[3])
            plt.show()
            plt.close()
            self.success_hist += [X[3]]
            print(f"at position {X[4]}")
            for t in range(num_eps):
              preds = self.policy(X[0]).squeeze()
              L = self.criterion(preds,X[1])

              self.optimizer.zero_grad()
              L.backward()
              self.optimizer.step()
              if t == num_eps-1:
                print(f"Loss: {L}")
                self.loss_hist.append(L.item())
            self.baseline = X[2]
            print(f"current objective: {self.baseline}")
        steps -= 1
      return self.baseline, self.loss_hist, self.success_hist

V = 4
E = int((V*(V-1))//2)
Env = LinEnv(V)
Env.reset()

wagner = nn.Sequential(
    nn.Linear(2*E, 2*E),
    nn.LeakyReLU(),
    nn.Linear(2*E,2*V),
    nn.ReLU(),
    nn.Linear(2*V,2*V),
    nn.ReLU(),
    nn.Linear(2*V,2*V),
    nn.ReLU(),
    nn.Linear(2*V,1),
    nn.Sigmoid())

summary(wagner,(2*E,))

player = Agent(Env, wagner, l_r=0.0001)
player.reset()

# Sample a trajectory
sts, acts, graphs, final_graph, rews = player.policy_sample()
print(acts)
print(len(graphs))
all_graphs = graphs.append(final_graph)

# Visualize the graphs in the trajectory using networkx
for i, graph in enumerate(graphs):
    nx.draw(graph)
    plt.title(f"Graph at step {i + 1}")
    plt.show()
    plt.close()

for i, graph in enumerate(graphs):
    print(f"Graph at step {i + 1}:")
    Env.graph = graph  # Set the current graph in the environment
    Env.render()  # Use the LinEnv's render method to visualize the graph

a_train = player.one_shot_training(1024,20)

a_train

print(a_train[3])

player.env.miner.invariants['wagner-1'](a_train[3])

Env.score_traj

H = player.success_hist

[player.env.miner.invariants['wagner-1'](H[i]) for i in range(len(H))]

W = 18
G = int((W*(W-1))//2)
Env_s = LinEnv(W)

wagner_18 = nn.Sequential(
    nn.Linear(2*G, 2*W),
    nn.LeakyReLU(),
    nn.Linear(2*W,2*W),
    nn.ReLU(),
    nn.Linear(2*W, 2),
    nn.ReLU(),
    nn.Linear(2,1),
    nn.Sigmoid())

summary(wagner_18,(2*G,))

player = Agent(Env_s, wagner_18, l_r=0.001)

player.one_shot_training(300,25)

def sess_gen(Env,Net,n_gen,conn=True):
  P = Env
  Eps = []
  for i in range(n_gen):
    P.reset()
    sts = []
    acts = []
    graphs = []
    while not P.done:
      sts.append(torch.Tensor(copy.deepcopy(P.state)))
      act = int(torch.bernoulli(Net(sts[-1])).item())
      acts.append(act)
      graphs.append(copy.deepcopy(P.graph))
      P.step(act)
    rews = copy.deepcopy(P.score_traj)
    co_adj = torch.stack(sts)
    co_adj_embedded = []
    if P.miner.invariants['num_cc'](graphs[-1]) == 1:
      co_adj_embedded = [co_adj]
      for p in range(P.num_edges-2,-1,-1):
        if P.miner.invariants['num_cc'](graphs[p]) == 1:
          co_adj_embedded.append(co_adj)
        else:
          break
    if co_adj_embedded != []:
      co_adj_tens = torch.stack(co_adj_embedded)
      for q in range(1,co_adj_tens.shape[0]):
        for r in range(Env.num_edges-q,Env.num_edges):
          for s in range(Env.num_edges-q,Env.num_edges):
            co_adj_tens[q,r,s] = 0
      invs = rews[Env.num_edges-co_adj_tens.shape[0]-1:]
      contr_ind = invs.index(max(invs))
      return co_adj_tens.shape, len(invs)



    if conn == True:
      stop = P.num_edges

      if P.miner.invariants['num_cc'](graph) == 1:
        Eps.append((sts,acts,rew,graph))
    else:
      Eps.append((sts,acts,rew,graph))
  return Eps

T = sess_gen(Env,wagner,1)

T

L = [1,2,3]
l = len(L)
L[l-1:]

def best_individuals(sesss, cap, duplicates=False):
  if sesss == []:
    return sesss
  sorted_lex = sorted(sesss, key=lambda x: x[1])
  repr = [sorted_lex[0]]
  if duplicates == False:
    for i in range(1,len(sorted_lex)):
      if sorted_lex[i][1] != repr[-1][1]:
        repr.append(sorted_lex[i])
  else:
    repr = sorted_lex
  sorted_repr = sorted(repr, key=lambda x: x[2], reverse=True)
  return sorted_repr[:cap]

best_cap = 32
buff_cap = 64

criterion = torch.nn.BCELoss()
optimizer = torch.optim.SGD(wagner.parameters(), lr=0.1)

num_eps = 16

def Agent(Env,Net,num_gens,best_cap,buff_cap,loss,opt,epochs,iterations=1000):
  buffer = []

  for _ in range(iterations):
    print(f"Iteration {_} starts")

    new_individuals = sess_gen(Env,Net,num_gens)
    best = best_individuals(new_individuals,best_cap)

    if best == []:
      continue

    new_mvp = best[0]
    print(f"Best current score: {new_mvp[2]}")
    nx.draw(new_mvp[3])
    plt.show()
    plt.close()

    improve = 0
    if buffer != []:
      improve = best[0][2] - buffer[0][2]

    best += buffer
    buffer = best_individuals(best, buff_cap)
    record = buffer[0]

    print(f"Best overall score: {record[2]}")

    if _ == 0 or improve > 0:

      inputs = []
      targets = []
      for j in range(len(buffer)):
        inputs += buffer[j][0]
        targets += buffer[j][1]


      inputs = torch.stack(inputs)
      targets = torch.Tensor(targets)

      for t in range(epochs):
        preds = Net(inputs).squeeze()
        L = loss(preds,targets)

        opt.zero_grad()
        L.backward()
        opt.step()
        if t == epochs-1:
          print(f"Loss: {L}")

Agent(Env,wagner,100,best_cap,buff_cap,criterion,optimizer,num_eps)

buffer = []

for _ in range(1000):

  print(f"Iteration {_} starts")

  new_individuals = sess_gen(Env,wagner,80)
  best = best_individuals(new_individuals, best_cap)

  if best == []:
    continue

  print(f"Best current score is {best[0][2]}, obtained by")
  nx.draw(best[0][3], with_labels=True)
  plt.show()
  plt.close()

  best += buffer
  buffer = best_individuals(best, buff_cap)

  print(f"Best overal score is {buffer[0][2]}")

  inputs = []
  targets = []
  for i in range(len(buffer)):
    inputs += buffer[i][0]
    targets += buffer[i][1]

  inputs = torch.stack(inputs)
  targets = torch.Tensor(targets)

  for t in range(num_eps):
    prediction = wagner(inputs)
    prediction = prediction.squeeze()
    loss = criterion(prediction, targets)

    optimizer.zero_grad()
    loss.backward()
    optimizer.step()
    if t == num_eps-1:
      print(f'Loss: {loss.item()}')

F = feats_miner(5)

S = sess_gen(Env,wagner,10)

g = best_individuals(S, 5)[0][3]

nx.adjacency_spectrum(g)

F.invariants["wagner-1"](g)

from torch.nn import Linear, Parameter
from torch_geometric.nn import MessagePassing
from torch_geometric.utils import add_self_loops, degree

class GCNConv(MessagePassing):
    def __init__(self, in_channels, out_channels):
        super().__init__(aggr='add')  # "Add" aggregation (Step 5).
        self.lin = Linear(in_channels, out_channels, bias=False)
        self.bias = Parameter(torch.Tensor(out_channels))

        self.reset_parameters()

    def reset_parameters(self):
        self.lin.reset_parameters()
        self.bias.data.zero_()

    def forward(self, x, edge_index):
        # x has shape [N, in_channels]
        # edge_index has shape [2, E]

        # Step 1: Add self-loops to the adjacency matrix.
        edge_index, _ = add_self_loops(edge_index, num_nodes=x.size(0))

        # Step 2: Linearly transform node feature matrix.
        x = self.lin(x)

        # Step 3: Compute normalization.
        row, col = edge_index
        deg = degree(col, x.size(0), dtype=x.dtype)
        deg_inv_sqrt = deg.pow(-0.5)
        deg_inv_sqrt[deg_inv_sqrt == float('inf')] = 0
        norm = deg_inv_sqrt[row] * deg_inv_sqrt[col]

        # Step 4-5: Start propagating messages.
        out = self.propagate(edge_index, x=x, norm=norm)

        # Step 6: Apply a final bias vector.
        out += self.bias

        return out

    def message(self, x_j, norm):
        # x_j has shape [E, out_channels]

        # Step 4: Normalize node features.
        return norm.view(-1, 1) * x_j

class MyAggregationLayer(MessagePassing):
    def __init__(self):
        super(MyAggregationLayer, self).__init__(aggr='add')

    def forward(self, x, edge_index):
        return self.propagate(edge_index, x=x)

    def message(self, x_j):
        return x_j  # Messaggio: i valori dei nodi vicini

    def aggregate(self, inputs, index, dim_size=None):
        return torch.any(inputs, dim=1, keepdim=True)  # Aggregazione: logical OR

    def update(self, aggr_out):
        return aggr_out  # Aggiornamento: il messaggio aggregato viene mantenuto senza modifiche

class GINConvolution(nn.Module):
    def __init__(self, num_nodes, units, activation=None):
        super(GINConvolution, self).__init__()
        self.units = units
        self.V = num_nodes
        self.E = int((self.V * (self.V-1))//2)
        self.activation = activation
        self.layer1 = nn.Linear(3,3)
        self.perceptron = nn.Sequential(nn.Linear(self.V, self.E),
                                        nn.ReLU(),
                                        nn.Linear(self.E, self.V),
                                        nn.LeakyReLU()
                                       )



        self.kernel = nn.Parameter(torch.Tensor(units, units))
        self.bias = nn.Parameter(torch.Tensor(units))

        self.reset_parameters()

np.zeros(10)

T = LinEnv(5)
T.reset()
while not T.done:
  T.step(1)
T.history

################ MAU ########################
# Metodo MC



def make_epsilon_greedy_policy(Q, epsilon, nA):
    """
    Creates an epsilon-greedy policy based on a given Q-function and epsilon.

    Args:
        Q: A dictionary that maps from state -> action-values.
            Each value is a numpy array of length nA (see below)
        epsilon: The probability to select a random action . float between 0 and 1.
        nA: Number of actions in the environment.

    Returns:
        A function that takes the observation as an argument and returns
        the probabilities for each action in the form of a numpy array of length nA.

    """
    def policy_fn(observation):
        A = np.ones(nA, dtype=float) * epsilon / nA
        best_action = np.argmax(Q[observation])
        A[best_action] += (1.0 - epsilon)
        return A
    return policy_fn

def mc_control_epsilon_greedy(env, num_episodes, horizon=1000, discount_factor=1.0, epsilon=0.1, render=False, save=False):
    """
    Monte Carlo Control using Epsilon-Greedy policies.
    Finds an optimal epsilon-greedy policy.

    Args:
        env: OpenAI gym environment.
        num_episodes: Number of episodes to sample.
        discount_factor: Gamma discount factor.
        epsilon: Chance the sample a random action. Float betwen 0 and 1.

    Returns:
        A tuple (Q, policy).
        Q is a dictionary mapping state -> action values.
        policy is a function that takes an observation as an argument and returns
        action probabilities
    """

    # Keeps track of sum and count of returns for each state
    # to calculate an average. We could use an array to save all
    # returns (like in the book) but that's memory inefficient.
    returns_sum = defaultdict(float)
    returns_count = defaultdict(float)

    # The final action-value function.
    # A nested dictionary that maps state -> (action -> action-value).
    Q = defaultdict(lambda: np.zeros(env.action_space.n))
    if save == True:
      graphs_ep = np.empty((num_episodes, env.num_edges+1), dtype=object)
      encs_ep = np.empty((num_episodes, env.num_edges, env.num_edges+1))
      ids_ep = np.empty((num_episodes, env.num_edges+1), dtype=tuple)
      adjs_ep = np.empty((num_episodes, env.num_nodes, env.num_nodes, env.num_edges+1))
      sar_ep = np.empty((num_episodes,5,env.num_edges))

    # The policy we're following
    policy = make_epsilon_greedy_policy(Q, epsilon, env.action_space.n)

    counter = None

    for i_episode in range(0, num_episodes):
        # Print out which episode we're on, useful for debugging.
        if (i_episode + 1) % 1000 == 0:
            print("\rEpisode {}/{}.".format(i_episode+1, num_episodes), end="")
            #print(states_per_episode.shape)
            sys.stdout.flush()

        # Generate an episode.
        # An episode is an array of (state, action, reward) tuples
        episode = []
        state = env.reset()

        if render == True:
          env.render()
        if save == True:
          graphs_ep[i_episode, 0] = copy.deepcopy(env.graph)
          encs_ep[i_episode,:,0] = copy.deepcopy(state[0][:env.num_edges])
          adjs_ep[i_episode,:,:,0] = copy.deepcopy(env.adj)

        state = env.obs_conversion()
        if save == True:
          ids_ep[i_episode, 0] = state
          sar_ep[i_episode,0,0] = state[0]
          sar_ep[i_episode,1,0] = state[1]
          sar_ep[i_episode,2,0] = state[2]

        for t in range(horizon):
            probs = policy(state)
            action = np.random.choice(np.arange(len(probs)), p=probs)
            next_state, reward, done = env.step(action)
            if save == True:
              sar_ep[i_episode,3,t] = action
              sar_ep[i_episode,4,t] = reward
            #print(next_state, reward, done)
            if render == True:
              env.render()
            if save == True:
              graphs_ep[i_episode, t+1] = copy.deepcopy(env.graph)
              encs_ep[i_episode,:,t+1] = next_state[:env.num_edges]
              adjs_ep[i_episode,:,:,t+1] = copy.deepcopy(env.adj)
            episode.append((state, action, reward))
            state = next_state
            state = env.obs_conversion()
            if save == True:
              ids_ep[i_episode, t+1] = state
              if not done:
                sar_ep[i_episode,0,t+1] = state[0]
                sar_ep[i_episode,1,t+1] = state[1]
                sar_ep[i_episode,2,t+1] = state[2]
            if done:
                break

        for i, (state, action, reward) in enumerate(episode):
            sa_pair = (state, action)
            G = sum([x[2] * (discount_factor ** j) for j, x in enumerate(episode[i:])])
            #if save_graphs == True:
            #  returns_per_episode[i_episode, i] = G
            returns_sum[sa_pair] += G
            returns_count[sa_pair] += 1.0
            Q[state][action] = returns_sum[sa_pair] / returns_count[sa_pair]



    # The policy is improved implicitly by changing the Q dictionary

    #print(graphs_per_episode)

    if save == True:
      return Q, policy, graphs_ep, encs_ep, ids_ep, adjs_ep, sar_ep
    else:
      return Q, policy

E = LinEnv(5, conn=True)

Q, policy, graphs_per_episode, vectors_per_episode, states_per_episode, matrixes_per_episode, sar_per_episode = mc_control_epsilon_greedy(E, num_episodes=1000, epsilon=0.9, render=False, save=True)

Exp = ExperimentData('wagner-1')

Exp.load_database('linear')

Exp.add_group('prova', meta=Exp.get_group_meta(E))

Exp.add_subgroup('prova', 'subprova', meta={'algorithm': 'MonteCarlo', 'policy': 'eps-greey'})

Exp.add_simulation('subprova', 'MC', (matrixes_per_episode, sar_per_episode), meta={'eps': 0.9})

Exp.data_path

Exp.groups_path

Exp.subgroups_dep

G = data_collector(path, 5, True)

inv = [fm.invariants['wagner-1'](g) for g in G]
for i in inv:
  print(i)

nx.adjacency_spectrum(G[0])

class LocEnv(gym.Env):
    def __init__(self, num_nodes, score='wagner-1', rew_type='sparse', stop_type='fixed', chaos=0):
        super(LocEnv, self).__init__()
        self.name = 'local'
        self.rew_types = {'sparse','sparse_max','cont','cont_var'}
        self.rew_type = rew_type
        self.score_fun = score
        self.num_nodes = num_nodes
        self.chaos = chaos
        self.miner = feats_miner(self.num_nodes)
        self.score_ev = self.miner.invariants[self.score_fun]
        self.num_edges = int((self.num_nodes * (self.num_nodes-1))//2)
        self.obs_dim = self.num_edges + self.num_nodes
        self.observation_space = gym.spaces.MultiBinary(self.obs_dim)
        self.initial_state = np.zeros(self.obs_dim)
        self.initial_state[self.num_edges] += 1
        self.state = copy.deepcopy(self.initial_state)
        self.action_space = gym.spaces.Tuple((gym.spaces.Discrete(self.num_nodes),gym.spaces.Discrete(2)))
        self.reward_range = (-float('inf'), float('inf'))
        self.initial_adj = np.zeros((self.num_nodes,self.num_nodes))
        self.adj = copy.deepcopy(self.initial_adj)
        self.pointer = 0
        self.initial_graph = nx.Graph(self.initial_adj)
        self.graph = copy.deepcopy(self.initial_graph)
        self.initial_scores = {'sparse': 0, 'sparse_max': 0, 'cont': self.score_ev(self.graph), 'cont_var': self.score_ev(self.graph)}
        self.initial_score = copy.deepcopy(self.initial_scores[rew_type])
        self.score = copy.deepcopy(self.initial_score)
        self.score_traj = [copy.deepcopy(self.initial_score)]
        self.time = 0
        self.done = False
        self.target_score = copy.deepcopy(self.initial_score)
        self.stop_types = {'fixed': 1, 'dynamic': copy.deepcopy(self.target_score), 'pass': 1}
        self.stop_type = stop_type
        self.stop_param = copy.deepcopy(self.stop_types[self.stop_type])
        if self.stop_type == 'pass':
          self.waiting = 0
        self.history = []

    def triangulate(self, i,j):
      i, j = i, j
      S = np.ones((self.num_nodes,self.num_nodes), dtype=np.int32)
      S = np.triu(S, k=1)
      s = 0
      kron = np.zeros(self.obs_dim)
      if i == j:
        return s, kron
      if i > j:
        h = j
        j = i
        i = h
      for p in range(j):
        for r in range(self.num_nodes):
          s += S[r,p]
      for q in range(i+1):
        s += S[i,j]
      return s, kron
      kron[s-1] += 1
      return s, kron

    def stop_check(self):
      stop = False
      if self.stop_type == 'fixed':
        if self.time == self.stop_param * self.num_edges:
          stop = True
      elif self.stop_type == 'dynamic':
        if self.score_traj[-1] > self.stop_param:
          stop = True
      elif self.stop_type == 'pass':
        if self.waiting == self.stop_param:
          stop = True
      return stop

    def step(self, action):
        sarsd = [0,0,0,0,0]
        ist = copy.deepcopy(self.state)
        e = self.num_edges
        g_id = int(np.dot(ist[:e], 2**np.arange(e)))
        i = self.pointer
        n_id = copy.deepcopy(i)
        sarsd[0] = (g_id,n_id)
        act = action
        sarsd[1] = act
        next_state = ist
        reward = 0
        if act[0] == i:
          if self.chaos == 1:
            cut = list(range(self.num_nodes))
            cut.remove(act[0])
            j = random.sample(cut)
            act[0] = j
        j = act[0]
        index = np.zeros(self.obs_dim)
        index[i+self.num_edges] -= 1
        index[self.num_edges+j] += 1
        next_state += index
        position, kron = self.triangulate(i,j)
        if position == 0 and self.stop_type == 'pass':
          self.waiting += 1
        if position != 0 and act[1] == 1:
          if hasattr(self, 'waiting'):
            self.waiting = 0
          next_state[position-1] = (next_state[position-1] + 1)%2
          self.adj[i,j] = (self.adj[i,j]+1)%2
          self.adj[j,i] = (self.adj[j,i]+1)%2
          self.graph = nx.Graph(self.adj)
          self.score = self.score_ev(self.graph)
        self.state = next_state
        self.score_traj.append(copy.deepcopy(self.score))
        self.pointer = j
        self.time += 1
        done = self.stop_check()
        if self.rew_type == 'sparse':
          if done:
            reward = self.score
        if self.rew_type == 'sparse_max':
          if done:
            reward = max(self.score_traj)
        if self.rew_type == 'cont':
          reward = self.score
        if self.rew_type == 'cont_var':
          reward = self.score_traj[-1] - self.score_traj[-2]
        sarsd[2] = reward
        ng_id = int(np.dot(next_state[:e], 2**np.arange(e)))
        nn_id = copy.deepcopy(self.pointer)
        sarsd[3] = (ng_id,nn_id)
        sarsd[4] = int(done)
        self.history.append(sarsd)
        return next_state, reward, done

    def reset(self):
        self.state = copy.deepcopy(self.initial_state)
        self.adj = copy.deepcopy(self.initial_adj)
        self.score = copy.deepcopy(self.initial_score)
        self.pointer = 0
        self.traj = [copy.deepcopy(self.initial_score)]
        self.time = 0
        self.done = False
        self.history = []
        if hasattr(self, 'waiting'):
          self.waiting = 0
        return self.initial_state, self.initial_score, self.done





class GlobEnv(gym.Env):
    def __init__(self, num_nodes, score='wagner-1', rew_type='sparse', stop_type='fixed'):
        super(GlobEnv, self).__init__()
        self.name = 'global'
        self.rew_types = {'sparse','sparse_max','cont','cont_var'}
        self.rew_type = rew_type
        self.score_fun = score
        self.num_nodes = num_nodes
        self.miner = feats_miner(self.num_nodes)
        self.score_ev = self.miner.invariants[self.score_fun]
        self.triangles = [(i*(i+1)//2) for i in range(self.num_nodes)]
        self.num_edges = int((self.num_nodes * (self.num_nodes-1))//2)
        self.observation_space = gym.spaces.MultiBinary(self.num_edges)
        self.initial_state = np.zeros(self.num_edges)
        self.state = copy.deepcopy(self.initial_state)
        self.action_space = gym.spaces.Discrete(self.num_edges+1)
        self.reward_range = (-float('inf'), float('inf'))
        self.initial_adj = np.zeros((self.num_nodes,self.num_nodes))
        self.adj = copy.deepcopy(self.initial_adj)
        self.initial_graph = nx.Graph(self.initial_adj)
        self.graph = copy.deepcopy(self.initial_graph)
        self.initial_scores = {'sparse': 0, 'sparse_max': 0, 'cont': self.score_ev(self.graph), 'cont_var': self.score_ev(self.graph)}
        self.initial_score = copy.deepcopy(self.initial_scores[rew_type])
        self.score = copy.deepcopy(self.initial_score)
        self.score_traj = [copy.deepcopy(self.initial_score)]
        self.done = False
        self.time = 0
        self.stop_types = {'fixed': 1, 'dynamic': copy.deepcopy(self.target_score), 'pass': 1}
        self.stop_type = stop_type
        self.stop_param = copy.deepcopy(self.stop_types[self.stop_type])
        if self.stop_type == 'pass':
          self.waiting = 0
        self.history = []

    def act_to_indx(self, act):
      i = 0
      j = 0
      while act > self.triangles[j]:
        j += 1
      if j != 0:
        i = act - (self.triangles[j-1] + 1)
      return i, j

    def stop_check(self):
      stop = False
      if self.stop_type == 'fixed':
        if self.time == self.stop_param * self.num_edges:
          stop = True
      elif self.stop_type == 'dynamic':
        if self.score_traj[-1] > self.stop_param:
          stop = True
      elif self.stop_type == 'pass':
        if self.waiting == self.stop_param:
          stop = True
      return stop

    def step(self, action):
        sarsd = [0,0,0,0,0]
        next_state = copy.deepcopy(self.state)
        e = self.num_edges
        sarsd[0] = int(np.dot(next_state, 2**np.arange(e)))
        sarsd[1] = action
        i, j = self.act_to_indx(action)
        if (i,j) == (0,0) and hasattr(self, 'waiting'):
          self.waiting += 1
        if (i,j) != (0,0):
          if hasattr(self, 'waiting'):
            self.waiting = 0
          next_state[action-1] = (next_state[action-1] + 1)%2
          self.adj[i,j] = (self.adj[i,j] + 1)%2
          self.adj[j,i] = (self.adj[j,i] + 1)%2
          self.graph = nx.Graph(self.adj)
        self.state = next_state
        self.score = self.score_ev(self.graph)
        self.score_traj.append(copy.deepcopy(self.score))
        self.time += 1
        done = self.stop_check()
        reward = 0
        if self.rew_type == 'sparse':
          if done:
            reward = self.score
        if self.rew_type == 'sparse_max':
          if done:
            reward = max(self.score_traj)
        if self.rew_type == 'cont':
          reward = self.score
        if self.rew_type == 'cont_var':
          reward = self.score_traj[-1] - self.score_traj[-2]
        sarsd[2] = reward
        sarsd[3] = int(np.dot(next_state, 2**np.arange(e)))
        sarsd[4] = int(done)
        self.history.append(sarsd)
        return next_state, reward, done

    def reset(self):
        self.state = copy.deepcopy(self.initial_state)
        self.adj = copy.deepcopy(self.initial_adj)
        self.score = copy.deepcopy(self.initial_score)
        self.traj = [copy.deepcopy(self.initial_score)]
        self.done = False
        self.time = 0
        if hasattr(self, 'waiting'):
          self.waiting = 0
        self.history = []
        return self.initial_state, self.initial_score, self.done



def brouwer_vector(G):
  spec = nx.laplacian_spectrum(G)
  V = len(spec)
  B = []
  eig_sum = 0
  for t in range(V-1,-1,-1):
    eig_sum += spec[t]
    m = G.number_of_edges()
    c = math.comb(V+1-t,2)
    score = eig_sum - (m+c)
    B.append(score)
  return B

brouwer_vector(a)

def edge_class(G):
  e = nx.number_of_edges(G)
  V = nx.number_of_nodes(G)
  E = int((V*(V-1))//2)
  H = torch.zeros((1,E))
  H[0,e-1] += 1
  return H

def tensor_data(L,size):
  l = len(L)
  card = int(l*size)
  S = random.sample(L, card)
  T_in = []
  T_out = []
  for G in S:
    T_in.append(nx.laplacian_spectrum(G))
    T_out.append(edge_class(G))
  T_in = np.array(T_in)
  T_in = torch.Tensor(T_in)
  T_out = torch.cat(T_out, dim=0)
  dataset = TensorDataset(T_in, T_out)
  return T_in, T_out, dataset

def arr_data_cc(L,size):
  l = len(L)
  card = int(l*size)
  S = random.sample(L,card)
  T_in = []
  T_out = []
  for G in S:
    T_in.append(nx.laplacian_spectrum(G))
    T_out.append(nx.number_connected_components(G))
  T_in = np.array(T_in)
  T_out = np.array(T_out)
  return T_in, T_out

def arr_data_ed(L,size):
  l = len(L)
  card = int(l*size)
  S = random.sample(L,card)
  T_in = []
  T_out = []
  for G in S:
    T_in.append(nx.laplacian_spectrum(G))
    T_out.append(nx.number_of_edges(G))
  T_in = np.array(T_in)
  T_out = np.array(T_out)
  return T_in, T_out

def np_torch_data(dataset):
  S = dataset.tensors[0]
  T = dataset.tensors[1]
  S_arr = S.numpy()
  T_arr = T.numpy()
  return S_arr, T_arr

G = L[138]
torch.reshape(torch.Tensor(np.real(nx.adjacency_spectrum(G))), (8,1))

def arr_data_eig(L,size):
  l = len(L)
  card = int(l*size)
  S = random.sample(L, card)
  T_in = []
  T_out = []
  for G in S:
    A = nx.adjacency_matrix(G)
    A = A.todense()
    A = torch.Tensor(A)
    v = G.number_of_nodes()
    C = torch.ones((v,1))
    D = torch.matmul(A, C)
    E = torch.matmul(A,D)
    F = torch.matmul(A, E)
    S = torch.reshape(torch.Tensor(np.real(nx.adjacency_spectrum(G))), (8,1))
    X = torch.cat([C,D,E,F,S], dim=1)
    X = X.numpy()
    T_in.append(X)
    T_out.append(nx.laplacian_spectrum(G))
  T_in = np.stack(T_in, axis=0)
  T_out = np.array(T_out)
  return T_in, T_out

def tensor_data_rad(array_dataset):
  T_in = []
  T_out = []
  arr_feats = array_dataset[0]
  arr_targets = array_dataset[1]
  v = np.shape(arr_feats)[1]
  aggregator = (1/v) * torch.ones((1,v))
  for i in range(len(arr_feats)):
    X = torch.Tensor(arr_feats[i])
    T_in.append(torch.matmul(aggregator, X))
    T_out.append(arr_targets[i][-1])
  T_in = torch.cat(T_in, dim=0)
  T_out = torch.Tensor(T_out)
  data = TensorDataset(T_in, T_out)
  return data

V = 8
E = int(((V*(V-1))//2))
units = 128

data_cc = arr_data_cc(L,1)

CcMLP = MLPClassifier(hidden_layer_sizes=(units, units, units), activation='relu', solver='sgd', learning_rate_init=0.001, momentum=0.9, max_iter=200, tol=1e-5, verbose=True)

data_ed = arr_data_ed(C,1)

EdgeMLP = MLPClassifier(hidden_layer_sizes=(units, units, units), activation='relu', solver='sgd', learning_rate_init=0.001, momentum=0.9, max_iter=1000, tol=1e-5, verbose=True)

data_eig = arr_data_eig(C,1)

tens_data_eig = tensor_data_rad(data_eig)

TT = random_split(tens_data_eig, [0.7, 0.3])

EigNet = nn.Sequential(nn.Linear(5,256), nn.ReLU(),
                       nn.Linear(256,256), nn.ReLU(),
                       nn.Linear(256,256), nn.ReLU(),
                       nn.Linear(256,64), nn.ReLU(),
                       nn.Linear(64,16), nn.ReLU(),
                       nn.Linear(16,1))
summary(EigNet, input_size=(1,5))

train = DataLoader(TT[0], batch_size=16, shuffle=True)
test = TT[1]

criterion = nn.L1Loss()
optimizer = optim.Adam(EigNet.parameters(), lr=0.001)

num_epochs = 100

for epoch in range(num_epochs):
    for inputs, targets in train:
        optimizer.zero_grad()
        outputs = EigNet(inputs)
        loss = criterion(outputs, targets)
        loss.backward()
        optimizer.step()

    print(f"Epoch {epoch+1}/{num_epochs}, Loss: {loss.item()}")

EigNet.eval()
with torch.no_grad():
    inputs, targets = test[:]
    outputs = EigNet(inputs)
    mse = nn.functional.l1_loss(outputs, targets)
print(f"MSE: {mse}")

EigNet(tens_data_eig.tensors[0][5])

tens_data_eig.tensors[1][5]

EigMLP = MLPRegressor(hidden_layer_sizes=(units, 64, 1), activation='relu', solver='adam')

X_train, X_test, y_train, y_test = train_test_split(data_eig[0], data_eig[1], test_size=0.2, random_state=42)

skf = KFold(n_splits=5)

scores_cc = cross_val_score(CcMLP, data_cc[0], data_cc[1], cv=skf, scoring='accuracy')

scores_cc

scores_ed = cross_val_score(EdgeMLP, data_ed[0], data_ed[1], cv=skf, scoring='accuracy')

scores_ed

class Brouwer_predict(nn.Module):
  def __init__(self, num_nodes, input_dim, units, *args, **kwargs):
    super().__init__(*args, **kwargs)
    self.num_nodes = num_nodes
    self.num_feats = input_dim
    self.units = units
    self.lin1 = nn.Linear(self.num_feats,2*self.num_feats)
    self.conv1 = torch_geometric.nn.GINConv(nn.Sequential(self.lin1,nn.ReLU()))
    self.lin2 = nn.Linear(2*self.num_feats,4*self.num_feats)
    self.conv2 = torch_geometric.nn.GINConv(nn.Sequential(self.lin2,nn.ReLU()))
    self.lin3 = nn.Linear(4*self.num_feats,units)
    self.lin4 = nn.Linear(units,units)
    self.lin5 = nn.Linear(units,1)

  def forward(self, x, edge_tensor):
    out = self.conv1(x, edge_tensor)
    out = self.conv2(out, edge_tensor)
    out = self.lin3(out)
    out = nn.functional.relu(out)
    out = self.lin4(out)
    out = nn.functional.relu(out)
    out = self.lin5(out)
    return out

G = C[-1]
G
torch_graph = from_networkx(G)
eds = torch_graph.edge_index
eds

Net = Brouwer_predict(8, 2, 32)

X = torch.ones((8,1))
X

A = torch.ones((8,8))-torch.eye(8)
A

Y = torch.matmul(A,X)
Y

Z = torch.cat([X,Y], dim=1)
Z

Net(Z, eds)

class EigToEdges(nn.Module):
  def __init__(self, input_dim, units, *args, **kwargs):
    super().__init__(*args, **kwargs)
    self.num_nodes = input_dim
    self.num_edges = int((self.num_nodes*(self.num_nodes-1))//2)
    self.lin1 = nn.Linear(self.num_nodes,units)
    self.lin2 = nn.Linear(units,units)
    self.lin3 = nn.Linear(units,units)
    self.lin4 = nn.Linear(units,units)
    self.lin5 = nn.Linear(units,self.num_edges)
    self.prob = nn.Softmax(dim=1)

  def forward(self, x):
    out = self.lin1(x)
    out = nn.functional.relu(self.lin2(out))
    out = nn.functional.relu(self.lin3(out))
    out = nn.functional.relu(self.lin4(out))
    out = self.lin5(out)
    out = self.prob(out)
    return out

EigClassifier = keras.Sequential()
EigClassifier.add(layers.Dense(units, activation=None))
EigClassifier.add(layers.Dense(units, activation='relu'))
EigClassifier.add(layers.Dense(units, activation='relu'))
EigClassifier.add(layers.Dense(units, activation='relu'))
EigClassifier.add(layers.Dense(E, activation='softmax'))
optim = optimizers.SGD(learning_rate=0.001, momentum=0.9)
EigClassifier.build((None,V))
EigClassifier.compile(loss="categorical_crossentropy", optimizer=optim)
EigClassifier.summary()

scores

Net = EigToEdges(8, 128)
summary(Net, (1,8))

dataset = tensor_data(C,1)

criterion = nn.MSELoss()
optimizer = torch.optim.SGD(Net.parameters(), lr=0.01)

folds = skf.split()

num_epochs = 100
for epoch in range(num_epochs):
  print(f"Epoch {epoch} starts")
  train_loader = DataLoader(dataset, batch_size=32, shuffle=True)
  for x, y in train_loader:
    optimizer.zero_grad()
    preds = Net(x)
    loss = criterion(preds, y)
    print(loss.item())
    loss.backward()
    optimizer.step()

nx.number_of_edges(L[56])

nx.draw(L[56])

x = torch.reshape(torch.Tensor(nx.laplacian_spectrum(L[56])), (1,8))
x

Net(x)

def pre_process(spec):
  V = len(spec)
  spec = torch.Tensor(spec)
  return torch.reshape(spec, (V,1))

X = pre_process(nx.laplacian_spectrum(L[5]))

class VectorRNN(nn.Module):
  def __init__(self, input_dim, hidden_dim):
    super(VectorRNN, self).__init__()
    self.hidden_dim = hidden_dim
    self.rnn = nn.RNN(input_dim, hidden_dim)

  def forward(self, x):
    out = self.rnn(x)
    return out[-1]

class EdgePredictor(nn.Module):
  def __init__(self, num_nodes, *args, **kwargs):
    super().__init__(*args, **kwargs)
    self.num_nodes = num_nodes
    self.num_edges = int((self.num_nodes*(self.num_nodes-1))//2)
    self.vrnn = VectorRNN(1, self.num_edges)
    self.lin1 = nn.Linear(self.num_edges,self.num_edges)
    self.lin2 = nn.Linear(self.num_edges,self.num_edges)
    self.lin3 = nn.Linear(self.num_edges,self.num_edges)
    self.prob = nn.Softmax(dim=1)

  def forward(self, x):
    out = self.vrnn(x)
    out = nn.functional.relu(self.lin1(out))
    out = nn.functional.relu(self.lin2(out))
    out = nn.functional.relu(self.lin3(out))
    out = self.prob(out)
    return out

EP = EdgePredictor(4)

EP(X)